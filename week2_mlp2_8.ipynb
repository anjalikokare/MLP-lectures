{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhUL7reJABpfXDj/2iukd4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjalikokare/MLP-lectures/blob/main/week2_mlp2_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Wrapper based filter selection**\n",
        " * rather than a scoring function it  use estimator class\n"
      ],
      "metadata": {
        "id": "1eEd0pRRim5o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recursive Feature Estimation**\n",
        "\n",
        "* recursivly remove features\n",
        "* removes the least important feature\n",
        "* repeat until desired no. of features are obtain"
      ],
      "metadata": {
        "id": "C-BlHDQfjMUW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SelectFromModel**\n",
        "* desired no. of imp features(as_specified with feature importance from the trained estimator )\n",
        "* the feature importance  obtain coef_feature_importance_ or importance_getter\n",
        "* its specify numerically or through string argument\n"
      ],
      "metadata": {
        "id": "YX5GY0wOkQBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sequently feature selection**\n",
        "* perform feature selction by selecting or deselecting feature one by one grttdy"
      ],
      "metadata": {
        "id": "H2yoCMr8mvaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forword one the two approaches\n",
        "\n",
        "* 1. **Forwarded selection** --> starting with 0 it find one best feature(repeat the process by adding a new feature to the set of selectes features)\n",
        "\n",
        "* 2. **backword selection** --> starting with all features and remove least imp features one by one folloeing the ideea of forward selection\n"
      ],
      "metadata": {
        "id": "zZKn17mZoQRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The direction parameter controls whether forward or backward SFS is used.\n",
        "* forward backword not yeild equivalent results\n",
        "* select the direction thet is efficient fot the required number of selected features:\n",
        "\n",
        "* when we want to select 7 out of 10 features\n",
        "* forward selection would need to perform 7iterations.\n",
        "* backword selection would only need to perform 3\n",
        "* backword selection seems to be reasonable choice here\n"
      ],
      "metadata": {
        "id": "4yB3nObs6KUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* SFS does not require the underlying model to expose a coef_ of  or  feature_importances_ attributes unlike in RFE and SelectFromModel.\n",
        "* SFS may be slower than RFE and SelectFromModel as it needs to evaluate more models compared to the other two approaches\n",
        "\n",
        "* for eg. the backword selection the iteration going from m features to m-1 features using k-fold cross-validation requires fitting m*k models while\n",
        "* RFE would only a single fit and\n",
        "* SelectFromModel performs a single fit and requires no iterations\n",
        "\n"
      ],
      "metadata": {
        "id": "5pC7Ymla-rKT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YzZcv7jV-rJQ"
      }
    }
  ]
}